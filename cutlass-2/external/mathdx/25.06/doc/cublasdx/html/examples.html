

<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Examples &#8212; cuBLASDx</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/nvidia-sphinx-theme.css?v=df3ac72c" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=757451c5"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.nvidia.com/cuda/cublasdx/_static/switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.4.0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="_static/nvidia.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Release Notes" href="release_notes.html" />
    <link rel="prev" title="cuBLASDx Python Bindings" href="python_bindings.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="0.4.0" />


  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="cuBLASDx - Home"/>
    <img src="_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="cuBLASDx - Home"/>
  
  
    <p class="title logo__title">cuBLASDx</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="cuBLASDx - Home"/>
    <img src="_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="cuBLASDx - Home"/>
  
  
    <p class="title logo__title">cuBLASDx</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="index.html">Documentation Home</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="requirements_func.html">Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_cublasdx.html">Using cuBLASDx</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Achieving High Performance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="api/operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/traits.html">Traits</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/methods.html">Execution Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/other_methods.html">Other Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/other_tensors.html">Tensor Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/other_shared.html">Shared Memory Management</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="python_bindings.html">cuBLASDx Python Bindings</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Examples</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/MathDx/cuBLASDx">GitHub Samples</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MathDx</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://developer.nvidia.com/cublasdx-downloads">cuBLASDx</a></li>
<li class="toctree-l1"><a class="reference external" href="https://developer.nvidia.com/cufftdx-downloads">cuFFTDx</a></li>
<li class="toctree-l1"><a class="reference external" href="https://developer.nvidia.com/cusolverdx-downloads">cuSolverDx</a></li>
<li class="toctree-l1"><a class="reference external" href="https://developer.nvidia.com/curanddx-downloads">cuRANDDx</a></li>
<li class="toctree-l1"><a class="reference external" href="https://developer.nvidia.com/nvcompdx-downloads">nvCOMPDx</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Examples</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="examples">
<span id="examples-label"></span><h1>Examples<a class="headerlink" href="#examples" title="Link to this heading">#</a></h1>
<p>The cuBLASDx library provides several block-level BLAS samples, covering basic GEMM operations with various
precisions and types, as well as special examples that highlight the performance benefits of cuBLASDx.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head" colspan="4"><p>Examples</p></th>
</tr>
<tr class="row-even"><th class="head" colspan="2"><p>Group</p></th>
<th class="head" rowspan="2"><p>Example</p></th>
<th class="head" rowspan="2"><p>Description</p></th>
</tr>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Subgroup</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td colspan="2"><p>Introduction Examples</p></td>
<td><p>introduction_example</p></td>
<td><p>cuBLASDx API introduction example</p></td>
</tr>
<tr class="row-odd"><td rowspan="12"><p>Simple GEMM Examples</p></td>
<td rowspan="5"><p>Basic Example</p></td>
<td><p>simple_gemm_fp32</p></td>
<td><p>Performs fp32 GEMM</p></td>
</tr>
<tr class="row-even"><td><p>simple_gemm_int8_int8_int32</p></td>
<td><p>Performs integral GEMM using Tensor Cores</p></td>
</tr>
<tr class="row-odd"><td><p>simple_gemm_cfp16</p></td>
<td><p>Performs complex fp16 GEMM</p></td>
</tr>
<tr class="row-even"><td><p>simple_gemm_fp8</p></td>
<td><p>Performs fp8 GEMM</p></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
</tr>
<tr class="row-even"><td rowspan="7"><p>Extra Examples</p></td>
<td><p>simple_gemm_leading_dimensions</p></td>
<td><p>Performs GEMM with non-default leading dimensions</p></td>
</tr>
<tr class="row-odd"><td><p>simple_gemm_fp32_decoupled</p></td>
<td><p>Performs fp32 GEMM using 16-bit input type to save on storage and transfers</p></td>
</tr>
<tr class="row-even"><td><p>simple_gemm_std_complex_fp32</p></td>
<td><p>Performs GEMM with <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">complex</span></code> as data type</p></td>
</tr>
<tr class="row-odd"><td><p>simple_gemm_mixed_precision</p></td>
<td><p>Performs GEMM with different data type for matrices <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code> and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code></p></td>
</tr>
<tr class="row-even"><td><p>simple_gemm_transform</p></td>
<td><p>Performs GEMM with transform operators</p></td>
</tr>
<tr class="row-odd"><td><p>simple_gemm_custom_layout</p></td>
<td><p>Performs GEMM with custom matrix layouts</p></td>
</tr>
<tr class="row-even"><td><p>simple_gemm_aat</p></td>
<td><p>Performs GEMM where C = A * A^T</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p>NVRTC Examples</p></td>
<td><p>nvrtc_gemm</p></td>
<td><p>Performs GEMM, kernel is compiled using NVRTC</p></td>
</tr>
<tr class="row-even"><td colspan="2" rowspan="3"><p>GEMM Performance</p></td>
<td><p>single_gemm_performance</p></td>
<td><p>Benchmark for single GEMM</p></td>
</tr>
<tr class="row-odd"><td><p>fused_gemm_performance</p></td>
<td><p>Benchmark for 2 GEMMs fused into a single kernel</p></td>
</tr>
<tr class="row-even"><td><p>device_gemm_performance</p></td>
<td><p>Benchmark entire device GEMMs using cuBLASDx for single tile</p></td>
</tr>
<tr class="row-odd"><td rowspan="8"><p>Advanced Examples</p></td>
<td rowspan="5"><p>Fusion</p></td>
<td><p>gemm_fusion</p></td>
<td><p>Performs 2 GEMMs in a single kernel</p></td>
</tr>
<tr class="row-even"><td><p>gemm_fft</p></td>
<td><p>Perform GEMM and FFT in a single kernel</p></td>
</tr>
<tr class="row-odd"><td><p>gemm_fft_fp16</p></td>
<td><p>Perform GEMM and FFT in a single kernel (half-precision complex type)</p></td>
</tr>
<tr class="row-even"><td><p>gemm_fft_performance</p></td>
<td><p>Benchmark for GEMM and FFT fused into a single kernel</p></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
</tr>
<tr class="row-even"><td rowspan="3"><p>Other</p></td>
<td><p>batched_gemm_fp64</p></td>
<td><p>Manual batching in a single CUDA block</p></td>
</tr>
<tr class="row-odd"><td><p>blockdim_gemm_fp16</p></td>
<td><p>BLAS execution with different block dimensions</p></td>
</tr>
<tr class="row-even"><td><p>gemm_device_partial_sums</p></td>
<td><p>Use extra register array in higher precision to offload partial accumulation</p></td>
</tr>
</tbody>
</table>
</div>
<section id="introduction-examples">
<span id="examples-introduction-examples-label"></span><h2>Introduction Examples<a class="headerlink" href="#introduction-examples" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">introduction_example</span></code></p></li>
</ul>
<p>Introduction examples are used in the documentation to explain the basics of the cuBLASDx library and its API. The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">introduction_example</span></code>
is used in the beginner’s guide to demonstrate GEMM with the cuBLASDx API: <a class="reference internal" href="using_cublasdx.html#intro1-label"><span class="std std-ref">General Matrix Multiply Using cuBLASDx</span></a>.</p>
</section>
<section id="simple-gemm-examples">
<span id="examples-simple-examples-label"></span><h2>Simple GEMM Examples<a class="headerlink" href="#simple-gemm-examples" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_fp32</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_fp32_decoupled</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_int8_int8_int32</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_cfp16</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_fp8</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_leading_dimensions</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_std_complex_fp32</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_mixed_precision</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_transform</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_custom_layout</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_aat</span></code></p></li>
</ul>
<p>Each of the examples listed above performs a general matrix multiply (<a class="reference internal" href="api/operators.html#function-operator-gemm-label"><span class="std std-ref">GEMM</span></a>) operation within a CUDA block.
The examples demonstrate how to create a complete BLAS description, allocate memory, set block dimensions, and configure the necessary amount of shared memory.
Input data (matrices <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code>, and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code>) is generated on the host, copied into a device buffer, and loaded into registers and shared memory.
The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">execute</span><span class="p">()</span></code> method computes GEMM and stores the results in either matrix <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code> or a register fragment accumulator. The results are then copied to
global memory and finally back to the host. All results are verified against cuBLAS.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_leading_dimensions</span></code> example shows how to set static (compile-time) leading dimensions for matrices <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code>, and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code>
using the <a class="reference internal" href="api/operators.html#leadingdimension-operator-label"><span class="std std-ref">LeadingDimension</span></a> operator.
For optimal performance, it is recommended to use the suggested leading dimensions from <a class="reference internal" href="api/traits.html#suggested-leading-dimension-of-trait-label"><span class="std std-ref">suggested_leading_dimension_of</span></a>.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_fp32_decoupled</span></code> example demonstrates how to decouple input precision from compute precision.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_std_complex_fp32</span></code> example demonstrates that cuBLASDx accepts matrices of types other than <a class="reference internal" href="api/traits.html#valuetype-block-trait-label"><span class="std std-ref">BLAS::a_value_type</span></a>, <a class="reference internal" href="api/traits.html#valuetype-block-trait-label"><span class="std std-ref">BLAS::b_value_type</span></a>, and <a class="reference internal" href="api/traits.html#valuetype-block-trait-label"><span class="std std-ref">BLAS::c_value_type</span></a>. In this case, the type is <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">complex</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span></code> from the CUDA C++ Standard Library, but it could also be <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">float2</span></code> provided by CUDA.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_mixed_precision</span></code> example shows how to compute a mixed-precision GEMM, where matrices <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code>, and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code> have different data precisions. Note that the scaling factors <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">alpha</span></code> and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">beta</span></code> are expected to have the same precision and type as the elements of matrix <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code>.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_transform</span></code> example demonstrates how to compute GEMM with transform operators <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">a_load_op</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">b_load_op</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">c_load_op</span></code>, and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">c_store_op</span></code>, which are applied element-wise when loading matrices <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code>, and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code>, and when storing matrix <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code>, respectively.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_custom_layout</span></code> example shows how to compute a GEMM where matrices <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code>, and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code> in shared memory use custom CuTe layouts.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">simple_gemm_aat</span></code> example demonstrates how to perform <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="o">^</span><span class="n">T</span></code>, where both <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code> and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span><span class="o">^</span><span class="n">T</span></code> occupy the same shared memory, allowing users to increase kernel occupancy or operate on larger matrices.</p>
</section>
<section id="nvrtc-examples">
<h2>NVRTC Examples<a class="headerlink" href="#nvrtc-examples" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">nvrtc_gemm</span></code></p></li>
</ul>
<p>The NVRTC example demonstrates how to use cuBLASDx with NVRTC runtime compilation to perform a GEMM.
The BLAS descriptions created with cuBLASDx operators are defined only in the device code.
The header file <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">cublasdx</span><span class="p">.</span><span class="n">hpp</span></code> is also included only in the device code that is passed to NVRTC.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since version 0.0.1, cuBLASDx has experimental support for compilation with <a class="reference external" href="https://docs.nvidia.com/cuda/nvrtc/index.html">NVRTC</a>.
See the <a class="reference internal" href="requirements_func.html#requirements-label"><span class="std std-ref">Requirements and Functionality</span></a> section.</p>
</div>
</section>
<section id="gemm-performance">
<h2>GEMM Performance<a class="headerlink" href="#gemm-performance" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">single_gemm_performance</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">fused_gemm_performance</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">device_gemm_performance</span></code></p></li>
</ul>
<p>The examples listed above illustrate the performance of cuBLASDx.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">single_gemm_performance</span></code> program demonstrates the performance of the cuBLASDx device function executing a general matrix multiply
(<a class="reference internal" href="api/operators.html#function-operator-gemm-label"><span class="std std-ref">GEMM</span></a>) operation. Users can easily modify this sample to test the performance
of a specific GEMM configuration.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">fused_gemm_performance</span></code> example shows the performance of two GEMM operations fused together into a single kernel.
The kernel execution time is compared against the time required by cuBLAS to perform the same calculations.
In both cases, the measured operation is run multiple times and the average speed is reported.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">device_gemm_performance</span></code> example compares the performance of cuBLASDx with cuBLAS when performing a GEMM that spans the entire GPU.
This example does not provide the best-performing tile sizes for all precisions; checking other datatypes with custom sizes may
require a parameter search. Global GEMM dimensions are dynamic values and can be passed as command line arguments:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform default size GEMM with cuBLASDx static tile specified in code</span>
./device_gemm_performance

<span class="c1"># Perform custom size GEMM with cuBLASDx static tile specified in code</span>
./device_gemm_performance<span class="w"> </span>m<span class="w"> </span>n<span class="w"> </span>k
</pre></div>
</div>
</section>
<section id="advanced-examples">
<h2>Advanced Examples<a class="headerlink" href="#advanced-examples" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fusion</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fft</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fft_fp16</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fft_performance</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">batched_gemm_fp64</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">blockdim_gemm_fp16</span></code></p></li>
<li><p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_device_partial_sums</span></code></p></li>
</ul>
<p>The advanced cuBLASDx examples demonstrate how cuBLASDx can be utilized to improve performance by fusing multiple
calculations into a single kernel, which ultimately reduces global memory accesses.</p>
<p>Examples <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fusion</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fft</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fft_fp16</span></code>, and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_fft_performance</span></code> show how to fuse multiple GEMMs or a GEMM and
an FFT together in one kernel. This is especially useful for pipelines with many small input matrices, as Dx libraries
can be easily adapted to batched execution by launching many CUDA blocks in a grid.</p>
<p>Examples <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">batched_gemm_fp64</span></code> and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">blockdim_gemm_fp16</span></code> demonstrate the use of the <a class="reference internal" href="api/operators.html#blockdim-operator-label"><span class="std std-ref">BlockDim</span></a> operator.
In <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">batched_gemm_fp64</span></code>, adding a 1D <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BlockDim</span></code> to a BLAS description and launching the kernel with 2D block dimensions allows for manual
batching of GEMMs in a single CUDA block (in contrast to batching by launching multiple blocks in a grid).
<code class="code highlight cpp docutils literal highlight-cpp"><span class="n">blockdim_gemm_fp16</span></code> includes multiple scenarios that demonstrate how to safely and correctly execute BLAS operations when the kernel is
launched with block dimensions different from the layout and the number of threads specified in <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BlockDim</span></code>.</p>
<p>The <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">gemm_device_partial_sums</span></code> example demonstrates how to use an extra register array in higher precision to offload partial accumulation
of the result of a GEMM every N iterations and avoid precision loss. This can be useful for improving the performance of GEMMs with a large
number of operations, or when the GEMM is part of a larger computation that requires a high precision accumulator.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="python_bindings.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">cuBLASDx Python Bindings</p>
      </div>
    </a>
    <a class="right-next"
       href="release_notes.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Release Notes</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-examples">Introduction Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-gemm-examples">Simple GEMM Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nvrtc-examples">NVRTC Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gemm-performance">GEMM Performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-examples">Advanced Examples</a></li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
<a class="footer-brand logo" href="https://www.nvidia.com">
  <img src="_static/nvidia-logo-horiz-rgb-1c-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA"/>
  <img src="_static/nvidia-logo-horiz-rgb-1c-wht-for-screen.svg" class="logo__image only-dark" alt="NVIDIA"/>
</a></div>
      
        <div class="footer-item">

<div class="footer-links">
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/">Privacy Policy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/">Manage My Privacy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/preferences/start/">Do Not Sell or Share My Data</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/">Terms of Service</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/">Accessibility</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/">Corporate Policies</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/product-security/">Product Security</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/contact/">Contact</a>
  
  
  
</div>
</div>
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright © 2022-2025, NVIDIA Corporation &amp; Affiliates. All rights reserved.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>